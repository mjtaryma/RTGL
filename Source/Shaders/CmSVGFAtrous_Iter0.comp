// Copyright (c) 2021 Sultim Tsyrendashiev
// 
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
// 
// The above copyright notice and this permission notice shall be included in all
// copies or substantial portions of the Software.
// 
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// SOFTWARE.
// 
// Copyright (c) 2018, Christoph Schied
// All rights reserved.
// 
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above copyright
//       notice, this list of conditions and the following disclaimer in the
//       documentation and/or other materials provided with the distribution.
//     * Neither the name of the Karlsruhe Institute of Technology nor the
//       names of its contributors may be used to endorse or promote products
//       derived from this software without specific prior written permission.
// 
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
// ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
// WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
// DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY
// DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
// (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
// ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

#version 460

// "Spatiotemporal Variance-Guided Filtering: Real-Time Reconstruction for Path-Traced Global Illumination", C.Schied et al.
// 4.3 Edge-avoiding a-trous wavelet transform

// This file is a copy of CmSVGFAtrous.comp
// It contains an optimized implementation for specific iteration.

#define DESC_SET_FRAMEBUFFERS 0
#define DESC_SET_GLOBAL_UNIFORM 1
#include "ShaderCommonGLSLFunc.h"
#include "BRDF.h"

layout(local_size_x = COMPUTE_SVGF_ATROUS_GROUP_SIZE_X, local_size_y = COMPUTE_SVGF_ATROUS_GROUP_SIZE_X, local_size_z = 1) in;

const int STEP_SIZE = 1;
const float SIGMA_LUMINANCE = 4.0;
// 3x3 box filter
const int FILTER_RADIUS = 1;
const float WAVELET_KERNEL[2][2] = 
{
    { 1.0, 0.5  },
    { 0.5, 0.25 }
};


// TODO: pack color values
struct AtrousData
{
    vec3    directDiffuseColor;
    // E5B9G9R9
    uint    encSpecularColor;
    // E5B9G9R9
    uint    encIndirColor;
    float   roughness;
    uint    encNormal;
    float   depth;
};

// Preloaded data for filter pixel data. Additional FILTER_RADIUS pixels at both ends for each dimension
const int SHARED_WIDTH = FILTER_RADIUS + COMPUTE_SVGF_ATROUS_GROUP_SIZE_X + FILTER_RADIUS;
shared AtrousData atrousData[SHARED_WIDTH][SHARED_WIDTH];
shared float directDiffuseVariance[SHARED_WIDTH][SHARED_WIDTH];


void fillFilterData( sampler2D   samplerDiff,
                     usampler2D  samplerSpec,
                     usampler2D  samplerIndir,
                     const ivec2 globalBasePix,
                     const int   sharedOffset )
{
    const ivec2 sharedPix = ivec2(sharedOffset % SHARED_WIDTH, sharedOffset / SHARED_WIDTH);
    const ivec2 globalPix = globalBasePix + sharedPix;

    AtrousData data;
    
    data.depth = texelFetch(framebufDepthWorld_Sampler, globalPix, 0).r;

    const vec4 cv           = texelFetch(samplerDiff,                       globalPix, 0);
    data.directDiffuseColor = cv.rgb;
    directDiffuseVariance[sharedPix.y][sharedPix.x] = cv.a;

    data.roughness        = texelFetch( framebufMetallicRoughness_Sampler, globalPix, 0 ).g;
    data.encSpecularColor = texelFetch( samplerSpec,                       globalPix, 0 ).r;
    data.encIndirColor    = texelFetch( samplerIndir,                      globalPix, 0 ).r;
    data.encNormal        = texelFetchEncNormal(                           globalPix );

    atrousData[sharedPix.y][sharedPix.x] = data;
}


void preload( sampler2D samplerDiff, usampler2D samplerSpec, usampler2D samplerIndir )
{
    const ivec2 globalBasePix = ivec2(gl_WorkGroupID.xy) * COMPUTE_SVGF_ATROUS_GROUP_SIZE_X - ivec2(FILTER_RADIUS);
    const int threadIndex = int(gl_LocalInvocationIndex);

    const int sharedCount = SHARED_WIDTH * SHARED_WIDTH;
    const int threadCount = COMPUTE_SVGF_ATROUS_GROUP_SIZE_X * COMPUTE_SVGF_ATROUS_GROUP_SIZE_X;
   
    // how many threads should load only one pixel
    const int oneLoadCount = 2 * threadCount - sharedCount;
    // how many threads should load two pixels
    // const int twoLoadCount = sharedCount - threadCount;

    if (threadIndex < oneLoadCount)
    {
        // first threads need to preload only 1 pixel
        fillFilterData(
            samplerDiff, samplerSpec, samplerIndir,
            globalBasePix, threadIndex);
    }
    else
    {
        // now threads are loading 2 neighboring pixels
        const int neighborsIndex = threadIndex - oneLoadCount;

        fillFilterData(
            samplerDiff, samplerSpec, samplerIndir,
            globalBasePix, oneLoadCount + neighborsIndex * 2 + 0);
       
        fillFilterData(
            samplerDiff, samplerSpec, samplerIndir,
            globalBasePix, oneLoadCount + neighborsIndex * 2 + 1);
    }
}

#define GET_ATROUS_DATA(offsetX, offsetY) (atrousData[gl_LocalInvocationID.y + FILTER_RADIUS + offsetY][gl_LocalInvocationID.x + FILTER_RADIUS + offsetX])
#define GET_DIR_DIFF_VARIANCE(offsetX, offsetY) (directDiffuseVariance[gl_LocalInvocationID.y + FILTER_RADIUS + offsetY][gl_LocalInvocationID.x + FILTER_RADIUS + offsetX])


float prefilterLuminanceVariance()
{
    const int GaussianFilterRadius = 1;
    const float gaussianKernel[2][2] = 
    {
        { 1.0 / 4.0, 1.0 / 8.0  },
        { 1.0 / 8.0, 1.0 / 16.0 }
    };

    float r = 0;

    for (int yy = -GaussianFilterRadius; yy <= GaussianFilterRadius; yy++)
    {
        for (int xx = -GaussianFilterRadius; xx <= GaussianFilterRadius; xx++)
        {
            const float variance = GET_DIR_DIFF_VARIANCE(xx, yy);
            const float w = gaussianKernel[abs(xx)][abs(yy)];

            r += variance * w;
        }
    }

    r = sqrt(max(r, 0.0));

    // also save the value for other iterations
    const ivec2 pix = ivec2(gl_GlobalInvocationID);
    imageStore(framebufAtrousFilteredVariance, pix, vec4(r));

    return r;
}


float dotEnc(uint n1, uint n2)
{
    return dot(decodeNormal(n1), decodeNormal(n2));
}


void atrous0(
    out vec3 outDiff, out float outVariance, 
    out vec3 outSpec,
    out vec3 outIndir)
{
    const ivec2 pix = ivec2(gl_GlobalInvocationID);
    const ivec3 chRenderArea = getCheckerboardedRenderArea(pix);


    const AtrousData center = GET_ATROUS_DATA(0, 0);


    if (center.depth < 0.0 || center.depth > MAX_RAY_LENGTH)
    {
        outVariance = 0.0;
        outDiff = vec3(0.0);
        outSpec = vec3(0.0);
        outIndir = vec3(0.0);

        return;
    }
    

    outVariance = GET_DIR_DIFF_VARIANCE(0, 0);
    outDiff     = center.directDiffuseColor;
    outSpec     = decodeE5B9G9R9(center.encSpecularColor);
    outIndir    = decodeE5B9G9R9(center.encIndirColor);

    const float l = getLuminance(outDiff);
    const float wLumMultiplier = 1.0 / (SIGMA_LUMINANCE * prefilterLuminanceVariance() + 0.00001);
   
    // the rougher the surface, the more blur to apply
    const float wRoughMultiplier = clamp(center.roughness * 30, 0, 1);

    float historyLengthSpec = texelFetch(framebufAccumHistoryLength_Sampler, pix, 0).b;
    float normalWeightScale = clamp(historyLengthSpec / 8, 0, 1);
	float normalWeightSpec = roughnessSquaredToSpecPower(center.roughness * center.roughness);
    normalWeightSpec = clamp(normalWeightSpec, 8, 1024);
	normalWeightSpec *= normalWeightScale;

    const float gradDepth = texelFetch( framebufDepthGrad_Sampler, pix, 0 ).r;
    const float isPrimary =
        wasSplit( texelFetch( framebufThroughput_Sampler, pix, 0 ).a ) ? 0.0 : 1.0;

    float weightSum = 1.0;
    float weightSumSpec = 1.0;
    float weightSumIndir = 1.0;

    for (int yy = -FILTER_RADIUS; yy <= FILTER_RADIUS; yy++)
    {
        for (int xx = -FILTER_RADIUS; xx <= FILTER_RADIUS; xx++)
        {
            if (xx == 0 && yy == 0)
            {
                continue;
            }

            const ivec2 offset = ivec2(xx * STEP_SIZE, yy * STEP_SIZE);
            const ivec2 pix_q = pix + offset;


            const AtrousData other = GET_ATROUS_DATA(offset.x, offset.y);


            const float l_q = getLuminance(other.directDiffuseColor);
            const float n_n = max(1.0 - isPrimary, dotEnc(center.encNormal, other.encNormal)); // always 1.0 if non-primary

            const float w_z = abs(center.depth - other.depth) / max(gradDepth * (abs(xx) + abs(yy)), 0.01) * isPrimary; // 0.0 if non-primary
            const float w_n = pow(n_n, 128.0);
            const float w_l = abs(l - l_q) * wLumMultiplier;

            // larger weight if roughness difference is small
            float w_r =  max(0, 1 - 10 * abs(center.roughness - other.roughness)) * wRoughMultiplier;

			if(normalWeightSpec > 0)
			{
				w_r *= pow(n_n, normalWeightSpec);
			}

            const float waveletW = WAVELET_KERNEL[abs(yy)][abs(xx)];
            const float isInside = float(testPixInRenderArea(pix_q, chRenderArea));

            const float wBase = exp(-w_z * w_z) * w_n * waveletW * isInside;

            const float wDiff      = wBase * exp(-w_l);
            const float wSpec      = wBase * w_r;
            const float wDiffIndir = wBase;


            outDiff += other.directDiffuseColor * wDiff;
            outSpec += decodeE5B9G9R9(other.encSpecularColor) * wSpec;
            outIndir += decodeE5B9G9R9(other.encIndirColor) * wDiffIndir;

            outVariance += GET_DIR_DIFF_VARIANCE(offset.x, offset.y) * wDiff * wDiff;

            weightSum += wDiff;
            weightSumSpec += wSpec;
            weightSumIndir += wDiffIndir;
        }
    }

    const float invWeightSum = 1.0 / weightSum;
    const float invWeightSumSpec = 1.0 / weightSumSpec;
    const float invWeightSumIdir = 1.0 / weightSumIndir;

    outDiff     *= invWeightSum;
    outVariance *= invWeightSum * invWeightSum;
    outSpec     *= invWeightSumSpec;
    outIndir    *= invWeightSumIdir;
}


void main()
{
    ivec2 pix = ivec2(gl_GlobalInvocationID);


    preload( framebufDiffPingColorAndVariance_Sampler,
             framebufSpecPingColor_Sampler,
             framebufIndirPing_Sampler );
    barrier();


    if (pix.x >= uint(globalUniform.renderWidth) || pix.y >= uint(globalUniform.renderHeight))
    {
        return;
    }


    float updatedVariance;
    vec3  filteredDiff;
    vec3  filteredSpec;
    vec3  filteredIndir;
    atrous0( filteredDiff, updatedVariance, filteredSpec, filteredIndir );


    // for the first iteration, save to color history buffer for temporal accumulation
    imageStore(framebufDiffColorHistory, pix, vec4(filteredDiff, updatedVariance)); 
    imageStoreSpecPongColor(             pix, filteredSpec); 
    imageStoreIndirPong(                 pix, filteredIndir); 
}
